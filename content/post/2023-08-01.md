# 2023-08-01 TIL

## 신경망

- 신경망: 시작은 인간의 뇌를 모방했으나, 현재 트렌드는 인간의 뇌를 모방한 처음과는 굉장히 많이 달라져 있음
- 신경망: 함수를 근사하는 모델, 그 과정에서 행렬 곱셈 및 비선형 변환이 수행됨
- 가장 단순한 형태: Model이 y = wx + b 형태인 linear neural network
  - 최적의 w와 b를 찾는 것이 목표
  - 이 경우 MSE를 사용하면, 최적의 w 와 b에 대해 analytic function이 존재하긴 함
  - 그러나 데이터가 아주 많은 경우 사용할 수 없음
- Loss function을 이용해, gradient의 반대 방향으로 w와 b를 업데이트 (학습) 하면 됨
  - 이 과정에서 step size를 잘 조정해야 함. 너무 크거나 작으면 학습이 안 됨
- M차원에서 N차원으로 가는 경우에도 행렬 연산을 통해 적용 가능
- 여러 선형 연산을 행렬을 통해 그냥 쌓는 건 의미가 없음
  - 이 사이에 non-linear한 transformation을 넣어 줘야 함
  - 이렇게 여러 layer를 쌓는 게 multi-layer-perceptron
  - 이렇게 해야 많은 표현력을 가지게 됨
- RELU, sigmoid, tanh 등 여러 activation function 존재
- Universal Approximation Theory: Hidden Layer가 하나 있는 모델은 대부분의 연속 함수를 표현 가능
  - 주의: 존재성만을 증명하지, 우리가 그 모델을 직접 만들 수 있다는 뜻은 아님

## 딥 러닝 최적화 기법

- Gradinet Descent: loss function의 일차 편미분을 이용해 local minimum을 찾는 게 목적
- 일반적으로 학습이 진행되면, train error는 줄어 들지만, test error는 어느 정도가 지나면 오히려 증가함
  - 모델이 너무 단순하면 under-fitting, 굉장히 복잡하면 over-fitting 된다고 함
- Cross validation: 학습 데이터를 k개로 나눠서, k - 1개로 학습하고, 남은 1개로 validation하는 과정
  - validation 데이터를 매 번 바꿔 가면서, 이 과정을 총 k번 반복
  - 테스트 데이터는 **절대!!!!!** 학습에 사용하면 안됨
- Bias and Variance
  - Variance: 출력이 얼마나 탄착군을 형성하는지, 낮을 수록 좋음
  - Bias: 출력이 평균적으로 얼마나 답과 떨어져 있는지, 낮을 수록 좋음
  - Cost = bias + variance + noise로 구성됨
  - 즉, bias와 variance를 둘 다 최적화 햘 수는 없음, trade-off 존재
- Bootstrapping
  - 학습 데이터를 subsampling 해서 여러 모델을 만들고, 해당 모델들의 결합을 통해 결과를 예측
  - Bagging: 여러 개의 모델을 독립적으로 만들어서 평균을 냄 (Ensemble)
  - Boosting: 한 모델에서 잘 안 된 내용을 바탕으로 다른 모델 학습, 이 과정을 통해 하나의 강한 모델 생성
- Practical Gradient Descent Method
  - Stochastic: 한 개의 데이터만 활용
  - Mini-batch: Batch Size 갯수의 데이터만 활용 (주로 사용)
  - Batch: 모든 데이터를 다 활용
  - Batch size는 중요하다! 작은 batch size가 더 유리 (물론 적당한 수준에서)
- GD 알고리즘 비교
  - SGD: 가장 기본적인 GD 방법, lr(learning rate)에 크게 영향 받기 때문에, 학습이 힘듦
  - Momentum: 이전 gradient를 조금 활용해서(관성) 학습을 해 보자
  - Nesterov: Momentum은 관성 때문에 minimum에 잘 못 빠짐, 이를 방지하기 위해 이전 gradient가 아닌 이전 gradient로 이동했을 때 위치의 gradient를 계산에 활용
  - Adagrad: 각 파라미터가 적게 변화해 왔으면 많이 변화시키고, 많이 변화해 왔으면 적게 변화시키는 방법
  - Adadelta: Adagrad의 업데이트 양이 0으로 수렴하는 걸 방지하기 위한 방법, lr이 없기 때문에, 튜닝이 불가능해서 잘 활용되지 않음
  - RMSprop: 역시 Adagrad를 활용, exponential average 활용
  - Adam: Adagrad와 Momentum의 아이디어를 합침
- Regularizaion
  - Generalization을 잘 하고 싶어서 실행하는 방법
  - Early Stopping: Validation error를 확인해서, loss가 어느 정도 커지면 멈추는 방법
  - Parameter Norm Penalty: 파라미터들의 값을 로스에 추가해서 너무 커지지 않도록 제어
  - Data Augmentation: 데이터를 추가하면 해결됨, 직접 데이터를 변환해서 넣어주는 방법 존재
  - Noise Robustness: weight / 인풋에 노이즈를 넣어 주면 조금 더 잘 됨
  - Label Smoothing: 서로 다른 label의 데이터를 섞음
  - Dropout: 일부 weight를 inference할 때 0으로 선정
  - Batch normalization: Internal Convariance Shift를 줄임, 논란이 약간 있음
