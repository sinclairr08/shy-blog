# Decision Tree

## Decision Tree

- 주어진 데이터가 어느 범주에 속하는지 알 수 있는 분류 문제에 사용 가능한 모델
  - 회귀 문제에도 사용 가능하지만, 분류 문제 기준으로 설명
- 기본적으로 Tree 구조를 가짐
  - 각 중간 노드는, 입력 데이터를 두 개의 영역으로 구분
    - 이 과정에서 데이터의 특정 기준을 이용해 영역을 결정
    - ex) 이를테면 특정 필드의 값이 10보다 큰 경우 / 작거나 같은 경우
  - 마지막 노드에서는 데이터의 범주를 결정하게 됨
- 기준을 삼을 때, 엔트로피가 가장 감소하는 방향으로 기준을 삼게 됨
  - 나뉘기 전의 데이터 집합이 X라고 가정
  - X를 Y, Z 두 개의 집합으로 나눈 경우, 엔트로피는 $p_yH(Y) + p_zH(Z)$가 됨
  - 이 엔트로피가 가장 최소가 되는 방향으로 데이터를 나누면 됨

## 왜 엔트로피가 최소가 되는 방향으로 나누는가?

- 만약 빨간 공과 파란 공이 4개씩 있다고 가정
- 이 공들을 두 개의 상자에 나눠 담는 경우, 여러 가지 방식으로 나눌 수 있음
  - 가장 엔트로피가 높게 나누는 방식은 각 상자에 빨간 공과 파란 공을 2개씩 담는 것
  - 가장 엔트로피가 낮게 나누는 방식은 한 상자에 빨간 공 4개를, 다른 상자에는 파란 공 4개를 담는 것
    - 이 경우 엔트로피가 0
- 후자가 더 데이터를 명확한 기준으로 잘 나눈 것이라고 볼 수 있음
  - Decision tree의 궁극적인 목적은, 기준을 이용해 데이터를 정확하게 분류하는 것이기 때문
  - 역으로 얘기하면, 후자의 방식이 가장 정보 획득량이 많다고 볼 수 있음!

## References

1. https://ratsgo.github.io/machine%20learning/2017/03/26/tree/

## 기타

- 주관이 많이 섞인 글이므로, 틀린 내용이 있을 수 있습니다
- 추후에 보완해서 읽기 쉽게 만들면서, 틀린 내용이 없도록 검수하겠습니다
